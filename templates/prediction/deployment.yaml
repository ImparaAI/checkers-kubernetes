apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: prediction
  labels:
    app: prediction
spec:
  replicas: 1
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 2
      maxUnavailable: 0
  template:
    metadata:
      labels:
        app: prediction
    spec:
      containers:
      - name: prediction
        {{- if .Values.prediction.gpu }}
        image: imparaai/checkers-prediction:gpu
        {{- else }}
        image: imparaai/checkers-prediction:cpu
        {{- end }}
        {{- if .Values.prediction.gpu }}
        resources:
          limits:
            nvidia.com/gpu: 1
        {{- end }}
        ports:
        - containerPort: 80
          name: http
        env:
          - name: USE_GPU
            value: {{ .Values.prediction.gpu | default "false" | quote}}
        readinessProbe:
          exec:
            command:
            - cat
            - /var/healthy
          initialDelaySeconds: 3
          periodSeconds: 3
      {{- if .Values.prediction.development_volume }}
        volumeMounts:
          - name: prediction
            mountPath: /var/app
      volumes:
      - name: prediction
        hostPath:
          path: {{ .Values.prediction.development_volume }}
      {{- end }}
      restartPolicy: Always